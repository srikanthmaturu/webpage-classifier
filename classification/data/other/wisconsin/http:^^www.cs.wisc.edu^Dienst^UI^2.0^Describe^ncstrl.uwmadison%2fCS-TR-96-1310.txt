server dienst v mime version content type text html trace cache low latency approach high bandwidth instruction fetching trace cache low latency approach high bandwidth instruction fetching eric rotenberg steve bennett jim smith cs tr april superscalar processors require sufficient instruction fetch bandwidth feed highly parallel execution cores fetch bandwidth determined number factors namely instruction cache hit rate branch prediction accuracy taken branches instruction stream taken branches introduce problem noncontiguous instruction fetching dynamic instruction sequence exists cache instructions contiguous cache locations report considers problem fetching noncontiguous blocks instructions single cycle propose trace cache special instruction cache captures dynamic instruction sequences line trace cache stores dynamic code sequence may contain one taken branches dynamic sequences built program executes predicted dynamic sequence exists trace cache fed directly decoders investigate methods fetching noncontiguous instruction sequences single cycle branch address cache collapsing buffer achieve high bandwidth feeding multiple noncontiguous fetch addresses interleaved cache performing complex alignment instructions come cache inevitably approach lengthens critical path instruction fetch unit extra stages fetch pipeline increase branch mispredict recovery time decreasing overall performance approach moves complexity due noncontiguous instruction fetching critical path onto fill side trace cache compare performance trace cache fetch designs first consider simple instruction fetching mechanisms predict one branch time fetch first taken branch also consider aggressive methods able fetch beyond multiple taken branches integer benchmarks trace cache improves performance average fetch unit limited one basic block per cycle fetch unit limited multiple contiguous basic blocks corresponding improvements floating point benchmarks trace cache consistently performs better high bandwidth fetch mechanisms studied even single cycle fetch latency assumed across mechanisms simulations realistic latencies high bandwidth approaches based pipeline stages instruction cache show trace cache clearly outperforms approaches average better next highest performer integer floating point benchmarks respectively view document display whole document one following formats postscript bytes compressed disk sent uncompressed print download selected pages granted permission non commercial reproduction distribution display performance technical report format thispermission period forty five days recenttime verified technical report still available fromthe computer science department university wisconsin madison underterms include permission rights reserved theauthor search ncstrlthis server operates uw madison computer sciences technical reports send email www cs wisc edu