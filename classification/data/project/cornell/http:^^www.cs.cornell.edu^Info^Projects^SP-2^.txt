mime version server cern date wednesday nov gmt content type text html content length last modified saturday mar gmt cucs ibm sp computer science ibm sp using cucs sp machine called granita eight nodes granita granita cucs login use sp log granita granita ve designated interactive nodes shells installed sh bsh csh ksh tcsh bash tsh experience problems first login try remove operating system specific stuff shell configuration file example aix arch command use uname instead file usr lpp bos readme contains information release aix used sp addition man use infoexplorer get information commands usage machine use program set remote display properly type info use poe run parallel jobs use neither active massages split c info l pe man poe read poe read run parallel programs use active messages split c information ibm sp hardware cornell theory center sp homegrown software general local software installed usr u sww sure usr u sww sp bin usr u sww sp gnu bin path split c split c simple extension c parallel computing provides global address space though global pointers dereferenced like regular pointers split phase assignment statements allow programmers hide latency remote accesses overlapping computation communication examples makefiles found sww sp split c bench cu bench working split c source sww sp etc sp setenv users non csh shells execute commands sww sp etc sp setenv non csh compile split c programs create makefile look samples various directories sww sp split c bench cu bench type gmake must include make split c makefile split c programs run way active messages programs e using amr scripts located usr u sww sp bin example run program foo processors type amr foo debugging split c debug split c program following steps need done include split c debug h insert splitc debug first statement executed splitc main compile run program described previous section see following message node commonly run granita debugging split c hit enter continue hitting return log onto node want debug want debug master node open new shell go directory program source located run gdb inside gdb file run attach pid pid proc id run process node debugged hit return node let computation proceed ve attached gdb run run stopped gdb set breakpoints look stack frames etc active messages active messages low overhead communication layer offers high performance communication many parallel machines native active messages layer sp available sp main performance characteristics sp one word round trip latency us asymptotic network bandwidth mb sp library found usr u sww sp lib libsp gam header file usr u sww sp include running programs use active messages source sww sp etc sp setenv read usr u sww sp gam doc runningprgms amr scripts located also usr u sww sp bin mpi mpi popular message passing interface portable parallel programs implementation mpi based mpich library running active messages sp header files located usr u sww sp include library file located usr u sww sp lib easiest way compile link script file ampicc built top xlc ampicc o foo c o foo also compile mpi programs xlc gcc split cc please look examples directory sww sp ampi examples information mpi programs run exactly like ordinary active messages programs e amr foo sure source sww sp etc sp setenv software software available granita granita also includes tcsh bash c set xlc fortran xlf xpdbx x matlab gnu software installed sww sp gnu includes emacs gmake gcc g gdb bison replicated locally usr local gnu bin problems experience difficulties sp please contact sp czar grzegorz czajkowski